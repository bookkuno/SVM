{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the Datasets\n",
    "data1A = pd.read_csv(\"/Users/book_kuno/Downloads/DDoS 2018/02-20-2018.csv\", low_memory=False)\n",
    "data2A = pd.read_csv(\"/Users/book_kuno/Downloads/DDoS 2018/02-21-2018.csv\", low_memory=False)\n",
    "\n",
    "#-----------Customized part for each particular datasets--------------\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['Flow ID', 'Src Port', 'Src IP', 'Dst IP']\n",
    "# Drop the specified columns from data1\n",
    "data1AD = data1A.drop(columns=columns_to_drop, errors='ignore')\n",
    "# Randomly sample 1/10 of the data\n",
    "data1 = data1AD.sample(frac=0.01, random_state=42)  # frac=0.1 means 10%, random_state ensures reproducibility\n",
    "print(data1.head())\n",
    "data2 = data2A.sample(frac=0.1, random_state=42)  # frac=0.1 means 10%, random_state ensures reproducibility\n",
    "print(data2.head())\n",
    "#-----------Customized part for each particular datasets--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the Data\n",
    "def preprocess_data(data):\n",
    "    data.columns = data.columns.str.strip()\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # Encode the target column ('Label')\n",
    "    encoder = LabelEncoder()\n",
    "    data['Label'] = encoder.fit_transform(data['Label'])\n",
    "    \n",
    "    # Select only numeric columns for scaling\n",
    "    numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numeric_columns.remove('Label')  # Exclude the target column\n",
    "    \n",
    "    # Check for infinite or extremely large values\n",
    "    data[numeric_columns] = data[numeric_columns].replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.dropna(subset=numeric_columns)\n",
    "    \n",
    "    # Scale the numeric feature columns\n",
    "    scaler = StandardScaler()\n",
    "    data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "    \n",
    "    X = data[numeric_columns]\n",
    "    y = data['Label']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X1, y1 = preprocess_data(data2)\n",
    "X2, y2 = preprocess_data(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train, Validate, Test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X1, y1, test_size=0.3, random_state=42)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class CustomSVM:\n",
    "    def __init__(self, C=1.0, kernel='rbf', gamma=1.0):\n",
    "        self.C = C\n",
    "        self.kernel_type = kernel\n",
    "        self.gamma = gamma\n",
    "        self.alpha = None\n",
    "        self.support_vectors = None\n",
    "        self.support_labels = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def rbf_kernel(self, X1, X2):\n",
    "        \"\"\"Radial Basis Function kernel.\"\"\"\n",
    "        return np.exp(-self.gamma * np.linalg.norm(X1[:, np.newaxis] - X2, axis=2)**2)\n",
    "    \n",
    "    def compute_kernel(self, X):\n",
    "        \"\"\"Compute the kernel matrix.\"\"\"\n",
    "        if self.kernel_type == 'rbf':\n",
    "            return self.rbf_kernel(X, X)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported kernel type.\")\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the SVM model.\"\"\"\n",
    "        m, n = X.shape\n",
    "        K = self.compute_kernel(X) * (y[:, np.newaxis] * y)\n",
    "        \n",
    "        # Define the dual optimization problem\n",
    "        def objective(alpha):\n",
    "            return 0.5 * np.dot(alpha, np.dot(K, alpha)) - np.sum(alpha)\n",
    "        \n",
    "        constraints = [\n",
    "            {'type': 'eq', 'fun': lambda alpha: np.dot(alpha, y)},\n",
    "            {'type': 'ineq', 'fun': lambda alpha: self.C - alpha},\n",
    "            {'type': 'ineq', 'fun': lambda alpha: alpha}\n",
    "        ]\n",
    "        \n",
    "        # Initial alpha values\n",
    "        alpha_init = np.zeros(m)\n",
    "        \n",
    "        # Solve the optimization problem\n",
    "        result = minimize(objective, alpha_init, constraints=constraints)\n",
    "        self.alpha = result.x\n",
    "        \n",
    "        # Extract support vectors\n",
    "        support_indices = self.alpha > 1e-5\n",
    "        self.support_vectors = X[support_indices]\n",
    "        self.support_labels = y[support_indices]\n",
    "        self.alpha = self.alpha[support_indices]\n",
    "        \n",
    "        # Calculate bias\n",
    "        self.bias = np.mean(\n",
    "            self.support_labels - np.sum(self.alpha * self.support_labels * K[support_indices], axis=1)\n",
    "        )\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using the trained SVM.\"\"\"\n",
    "        K = self.rbf_kernel(X, self.support_vectors)\n",
    "        predictions = np.sum(K * (self.alpha * self.support_labels), axis=1) + self.bias\n",
    "        return np.sign(predictions)\n",
    "\n",
    "# Usage of CustomSVM\n",
    "custom_svm = CustomSVM(C=1.0, kernel='rbf', gamma=0.1)\n",
    "custom_svm.fit(X_train.values, y_train.values)\n",
    "y_val_pred_custom = custom_svm.predict(X_val.values)\n",
    "\n",
    "# Validate\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Validation Results (Custom SVM):\")\n",
    "print(classification_report(y_val, y_val_pred_custom))\n",
    "\n",
    "# Custom Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "best_params = None\n",
    "best_score = -np.inf\n",
    "\n",
    "for C in param_grid['C']:\n",
    "    for gamma in param_grid['gamma']:\n",
    "        custom_svm = CustomSVM(C=C, kernel='rbf', gamma=gamma)\n",
    "        \n",
    "        # Perform 3-fold cross-validation\n",
    "        scores = []\n",
    "        for train_idx, val_idx in KFold(n_splits=3, shuffle=True, random_state=42).split(X_train):\n",
    "            X_train_cv, X_val_cv = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_train_cv, y_val_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            # Train and validate\n",
    "            custom_svm.fit(X_train_cv.values, y_train_cv.values)\n",
    "            y_val_pred = custom_svm.predict(X_val_cv.values)\n",
    "            scores.append(accuracy_score(y_val_cv, y_val_pred))\n",
    "        \n",
    "        # Average validation score\n",
    "        mean_score = np.mean(scores)\n",
    "        print(f\"C={C}, gamma={gamma}, mean_accuracy={mean_score:.4f}\")\n",
    "        \n",
    "        # Track the best parameters\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_params = {'C': C, 'gamma': gamma}\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "final_svm = CustomSVM(C=best_params['C'], kernel='rbf', gamma=best_params['gamma'])\n",
    "final_svm.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred_custom = final_svm.predict(X2.values)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"Test Results (Custom SVM):\")\n",
    "print(confusion_matrix(y2, y_test_pred_custom))\n",
    "print(classification_report(y2, y_test_pred_custom))\n",
    "print(\"Accuracy:\", accuracy_score(y2, y_test_pred_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Dimensionality Reduction for Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Function to plot predicted datapoints with class names\n",
    "def plot_predicted_data_with_class_names(X, y_true, y_pred, encoder, title=\"Predicted Data Points\"):\n",
    "    # Reduce dimensionality to 2D for visualization using PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    # Get all possible class labels from the test data and predictions\n",
    "    all_classes = np.union1d(np.unique(y_true), np.unique(y_pred))\n",
    "    class_names = encoder.inverse_transform(all_classes)\n",
    "    \n",
    "    # Define a color map for all possible classes\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF', '#00FF00', '#FFA500', '#800080', '#FFFF00', '#00FFFF', '#8B4513'])\n",
    "    num_classes = len(all_classes)\n",
    "    \n",
    "    # Create a scatter plot with predicted labels\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred, cmap=cm_bright, edgecolor='k', alpha=0.8)\n",
    "    \n",
    "    # Add a legend with class names\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                          markerfacecolor=cm_bright(i / (num_classes - 1)), markersize=10)\n",
    "               for i in range(num_classes)]\n",
    "    plt.legend(handles, class_names, title=\"Classes\", loc=\"best\")\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Assuming X2, y2 (true test labels), y_test_pred_custom (predictions), and encoder are already defined\n",
    "plot_predicted_data_with_class_names(X2.values, y2.values, y_test_pred_custom, encoder, title=\"Custom SVM Predicted Data Points with Class Names\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
